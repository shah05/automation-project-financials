{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A : Data Massage\n",
    "\n",
    "### 1. Declare input and output file name.\n",
    "\n",
    "Input file needs to be in CSV format for faster loading.\n",
    "\n",
    "#### me2l_input_file = input/ME2L_20210227.csv\n",
    "\n",
    "Place the file in the *input* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "me2l_input_file = \"input/ME2L_20210327.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Declare output file name.\n",
    "\n",
    "Output file name in Excel (xslx) format.\n",
    "\n",
    "#### me2l_output_file = output/output_me2l_20210227.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "me2l_output_file = \"output/ME2L_20210327_output.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Indicate US/SGD Dollar currency rate to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set USD/SGD Currency rate here.\n",
    "usd_currency_rate = 4.1\n",
    "sgd_currency_rate = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Read input file\n",
    "\n",
    "If file contains large data sets with alot of columns, reading will take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> DATA LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TM36250\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "df1 = pd.read_csv(me2l_input_file,parse_dates=True, encoding='ISO-8859-1',thousands=',');\n",
    "print(' ===> DATA LOADED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Remove unwanted columns.\n",
    "\n",
    "This will allow processing of data faster since unwanted data is discarded.Columns removed:\n",
    "- Deletion Indicator\n",
    "- Req. Tracking Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> DROP COLUMNS COMPLETED\n"
     ]
    }
   ],
   "source": [
    "df1.drop(columns=['Deletion Indicator','Req. Tracking Number'],inplace=True);\n",
    "print(' ===> DROP COLUMNS COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Insert 'Vendor Code' and 'Vendor' column at the begining.\n",
    "\n",
    "Extract Vendor Code info and Vendor Name info from 'Vendor/supplying plant' column.\n",
    "\n",
    "Based on old SAP entries there are multiple Vendor Code entries which are similar but Vendor name spelling is different. Example:\n",
    "- Vendor Code = 1107060 , Vendor Name = Corporation A Sdn. Bhd.\n",
    "- Vendor Code = 1107060 , Vendor Name = Corporation A Technologies\n",
    "\n",
    "\n",
    "Need to rearrange all PO so that it is assigned to one unique Vendor Code and one Vendor Name. So that in final summary there are no multiple vendor name entries that refers to a single vendor.\n",
    "\n",
    "Once this process done, remove the 'Vendor/supplying plant' column since it is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> VENDOR CODE & NAME ASSIGNMENT COMPLETED..\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "#Extract Vendor code and Vendor name and insert as new columns\n",
    "extract_vendor = df1[\"Vendor/supplying plant\"].str.split(\" \", n = 1, expand = True) \n",
    "df1.insert(0,'Vendor Code', extract_vendor[0]);\n",
    "df1.insert(1,'Vendor', extract_vendor[1]);\n",
    "\n",
    "#Create a separate dataframe for vendor code and vendor name\n",
    "vendor_list={'Vendor Code': extract_vendor[0],'Vendor Unique': extract_vendor[1]}\n",
    "df_vendor = pd.DataFrame(vendor_list, columns = ['Vendor Code', 'Vendor Unique'])\n",
    "\n",
    "#Remove duplicate entries in vendor dataframe\n",
    "df_vendor.drop_duplicates(inplace=True)\n",
    "#Remove duplicates in vendor code but having multiple versions of vendor name. Only keep the first one found. \n",
    "#There will only be one 1x vendor code tied to 1x vendor name.\n",
    "df_vendor.drop_duplicates(subset='Vendor Code',keep='first',inplace=True)\n",
    "#Sort the values in ascending manner\n",
    "df_vendor.sort_values(by=['Vendor Code'],inplace=True)\n",
    "\n",
    "#Vlookup between both df1 and df_vendor to streamline the vendor name.\n",
    "df1 = pd.merge(df1,df_vendor,on ='Vendor Code',how ='inner')\n",
    "#Drop the initial Vendor column and Vendor/supplying plant\n",
    "df1.drop(columns=['Vendor'],inplace=True)\n",
    "df1.drop(columns=['Vendor/supplying plant','Outline Agreement'],inplace=True)\n",
    "\n",
    "#Rename Vendor name columns\n",
    "df1.rename(columns={'Vendor Unique': 'Vendor'}, inplace=True)\n",
    "\n",
    "#Rearrange columns to place vendor name in 2nd position.\n",
    "df1 = df1[['Vendor Code','Vendor', 'Purchasing Document', 'Short Text', 'Currency',\n",
    "       'Acct Assignment Cat.', 'Document Date', 'Order Quantity', 'Net price',\n",
    "       'Net Order Value', 'Still to be delivered (qty)',\n",
    "       'Still to be delivered (value)', 'Still to be invoiced (qty)',\n",
    "       'Still to be invoiced (val.)']]\n",
    "\n",
    "print(' ===> VENDOR CODE & NAME ASSIGNMENT COMPLETED..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Classify each PO according to CAPEX/OPEX category.\n",
    "\n",
    "Use values from 'Acc Assignment Cat.' as reference for classification.\n",
    "- CAPEX (A, N, P, X)\n",
    "- OPEX (F, K, Blank)\n",
    "\n",
    "Add a new column called 'Capex/Opex' at the end of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> CAPEX/OPEX CATEGORY ASSIGNMENT COMPLETED..\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "def assign_capex_opex(code):\n",
    "    if(code == 'A' or code == 'N' or code == 'P' or code == 'X'):\n",
    "        return 'CAPEX'\n",
    "    elif (code == 'F' or code == 'K' or code == '' or np.isnan(code)):\n",
    "        return 'OPEX'\n",
    "\n",
    "df1['Capex/Opex'] = df1.apply(lambda row: assign_capex_opex(row['Acct Assignment Cat.']),axis=1)\n",
    "print(' ===> CAPEX/OPEX CATEGORY ASSIGNMENT COMPLETED..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculate Aging, PO Category & PO Year\n",
    "\n",
    "Add 2 new columns to input the Aging info:\n",
    "- 'Aging' = shows aging in number of days\n",
    "- 'Aging (Months & Days)' = shows aging in number of months and remaining days\n",
    "\n",
    "Check PO Category if the value in 'Document Date' column is similar to current year. If not then PO < Current Year\n",
    "\n",
    "Check PO Year using the 'Document Date' column. Extract year info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> AGING, PO CATEGORY & YEAR ASSIGNMENT COMPLETED..Executed in 22.761953592300415s\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "print(' ===> Running..')\n",
    "def calculate_aging_days(doc_date,date_now):\n",
    "    po_date = datetime.datetime.strptime(doc_date, '%d/%m/%Y')\n",
    "    delta = now - po_date\n",
    "    return int(delta.days)\n",
    "\n",
    "def calculate_aging_months_days(aging_days):\n",
    "    months = int(aging_days/30)\n",
    "    remaining_days = int(aging_days%30)\n",
    "    return str(months) + ' months ' + str(remaining_days) + ' days'\n",
    "\n",
    "def assign_po_year(doc_date):\n",
    "    po_date = datetime.datetime.strptime(doc_date, '%d/%m/%Y')\n",
    "    return po_date.year\n",
    "\n",
    "def assign_po_category(doc_date,current_year):\n",
    "    po_date = datetime.datetime.strptime(doc_date, '%d/%m/%Y')\n",
    "    return 'PO ' + str(now.year) if  po_date.year == now.year else 'PO <' + str(now.year)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "df1['Aging Days'] = df1.apply(lambda row: calculate_aging_days(row['Document Date'],now),axis=1)\n",
    "df1['PO Year'] = df1.apply(lambda row: assign_po_year(row['Document Date']),axis=1)\n",
    "df1['PO Category'] = df1.apply(lambda row: assign_po_category(row['Document Date'],datetime.datetime.now().year),axis=1)\n",
    "df1['Aging (Months & Days)'] = df1.apply(lambda row: calculate_aging_months_days(row['Aging Days']),axis=1)\n",
    "df1['PO Category'] = df1.apply(lambda row: assign_po_category(row['Document Date'],datetime.datetime.now().year),axis=1)\n",
    "\n",
    "end = time.time()\n",
    "print(' ===> AGING, PO CATEGORY & YEAR ASSIGNMENT COMPLETED..Executed in ' + str(end-start)+ 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Calculate Aging Category\n",
    "\n",
    "Classify each PO into the following categories:\n",
    "- ( <6 Months )\n",
    "- ( >6 Months )\n",
    "- ( >18 Months )\n",
    "\n",
    "Add a new column 'Aging Category' at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> AGING CATEGORY ASSIGNMENT COMPLETED\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "df1.loc[ (df1['Aging Days'] <= 182),'Aging Category'] = '<6 Months'\n",
    "df1.loc[ (df1['Aging Days'] > 182) & (df1['Aging Days'] <= 540),'Aging Category'] = '>6 Months'\n",
    "df1.loc[ (df1['Aging Days'] > 540),'Aging Category'] = '>18 Months'\n",
    "print(' ===> AGING CATEGORY ASSIGNMENT COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Assign GR status\n",
    "\n",
    "Status can either be 'Open' or 'Closed' depending on there are still value to be delivered. Use the column 'Still to be delivered (value)' as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> GR STATUS ASSIGNMENT COMPLETED\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "df1['GR Status'] = df1['Still to be delivered (value)'].apply(lambda x: 'Open' if x > 0 else 'Closed')\n",
    "print(' ===> GR STATUS ASSIGNMENT COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Assign GRIR Status\n",
    "Status can be either 'Open' or 'Closed' depending on value in column 'Still to be invoiced (val.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> GRIR STATUS ASSIGNMENT COMPLETED\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "df1['GRIR Status'] = df1['Still to be invoiced (val.)'].apply(lambda x: 'Closed' if x > -0.1 and x < 0.1 else 'Open')\n",
    "print(' ===> GRIR STATUS ASSIGNMENT COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Assign PO Category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> ASSIGN PO CATEGORY COMPLETED\n"
     ]
    }
   ],
   "source": [
    "df1['PO Status'] = np.where((df1['GR Status'] == 'Closed') & (df1['GRIR Status'] == 'Closed'), 'Closed', 'Open')\n",
    "print(' ===> ASSIGN PO CATEGORY COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Calculate Still to be delivered (MYR-Value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> COMPLETED\n"
     ]
    }
   ],
   "source": [
    "def convert_to_myr(value,currency):\n",
    "    if currency == 'USD':\n",
    "        return value*usd_currency_rate\n",
    "    elif currency == 'SGD':\n",
    "        return value*sgd_currency_rate\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "df1['Still to be delivered (MYR-Value)'] = df1.apply(lambda row: convert_to_myr(row['Still to be delivered (value)'],row['Currency']),axis=1)\n",
    "df1['Still to be invoiced (MYR-Value)'] = df1.apply(lambda row: convert_to_myr(row['Still to be invoiced (val.)'],row['Currency']),axis=1)\n",
    "print(' ===> COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B : Prepare Report\n",
    "\n",
    "### 1. Write data to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> WRITE OPERATION TO DATA WORKSHEET COMPLETED..Executed in 55.16636562347412s\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "writer = pd.ExcelWriter(me2l_output_file, engine='xlsxwriter',datetime_format='dd mmmm  yyyy')\n",
    "start = time.time()\n",
    "\n",
    "df1.to_excel(writer, sheet_name='data',index=False)\n",
    "end = time.time()\n",
    "print(' ===> WRITE OPERATION TO DATA WORKSHEET COMPLETED..Executed in ' + str(end-start)+ 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> COLUMN CONVERSION TO NUMBER FORMAT COMPLETED\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "#Convert certain columns to number format\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['data']\n",
    "print(' ===> COLUMN CONVERSION TO NUMBER FORMAT COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PO Summary List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> COLUMN CONVERSION TO DATE FORMAT COMPLETED\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "df1['Document Date'] = pd.to_datetime(df1['Document Date'], format=\"%d/%m/%Y\")\n",
    "print(' ===> COLUMN CONVERSION TO DATE FORMAT COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> GROUPING OF PO LINE ITEMS COMPLETED\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "df2 = df1.groupby(['Purchasing Document','Vendor','Capex/Opex', 'Currency','Document Date']).agg('sum')\n",
    "df2.drop(columns=['Aging Days','PO Year', 'Net price','Order Quantity','Still to be delivered (qty)','Still to be invoiced (qty)'],inplace=True)\n",
    "print(' ===> GROUPING OF PO LINE ITEMS COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> Running..\n",
      " ===> WRITE OPERATION TO PO WORKSHEET COMPLETED..Executed in 33.05499505996704s\n"
     ]
    }
   ],
   "source": [
    "print(' ===> Running..')\n",
    "start = time.time()\n",
    "df2.to_excel(writer, sheet_name='PO',merge_cells=False)\n",
    "\n",
    "writer.save()\n",
    "end = time.time()\n",
    "print(' ===> WRITE OPERATION TO PO WORKSHEET COMPLETED..Executed in ' + str(end-start)+ 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
