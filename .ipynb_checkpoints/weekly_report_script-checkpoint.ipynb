{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A : Data Massage\n",
    "\n",
    "### 1. Declare input file names.\n",
    "\n",
    "File needs to be in CSV format for faster loading.\n",
    "\n",
    "#### Input 1 = ME2L_W01.CSV\n",
    "#### Input 2 = ME2L_W02.CSV\n",
    "\n",
    "Place the 2 input files in the current directory as the script file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# me2l_w01_file = \"test/me2l_w01x.xlsx\"\n",
    "# df1 = pd.read_excel(me2l_w01_file,sheet_name='Raw');\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "me2l_w01_file = \"test/me2l_w01.csv\"\n",
    "me2l_w02_file = \"test/me2l_w02.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read input files\n",
    "\n",
    "If file contains large data sets with alot of columns, reading will take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'me2l_w01_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-68e8dbf25f32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load first input file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mme2l_w01_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ISO-8859-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# df1.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'me2l_w01_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Load first input file\n",
    "df1 = pd.read_csv(me2l_w01_file,parse_dates=True, encoding='ISO-8859-1');\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second input file\n",
    "df2 = pd.read_csv(me2l_w02_file,parse_dates=True);\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract PO with correct CAPEX Category from ME2L_W02 \n",
    "\n",
    "Capex Category = (A, N, P, X).\n",
    "But how to check if the project is deployment,operation related ? Any keyword or vendor as filters ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "capex_w02 = df2[(df2['Acct Assignment Cat.'] == 'A') |\n",
    "                (df2['Acct Assignment Cat.'] == 'N') |\n",
    "                (df2['Acct Assignment Cat.'] == 'P') |\n",
    "                (df2['Acct Assignment Cat.'] == 'X') \n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Append extraction from ME2L_W02 to ME2L_W01\n",
    "\n",
    "Data will be pasted at the bottom of ME2L_W01 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(capex_w02);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Remove unwanted columns.\n",
    "\n",
    "This will allow processing of data faster since unwanted data is discarded.Columns removed:\n",
    "- Deletion Indicator\n",
    "- Req. Tracking Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['Deletion Indicator','Req. Tracking Number']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Insert 'Vendor Code' and 'Vendor' column at the begining.\n",
    "\n",
    "Extract Vendor Code info and Vendor Name info from 'Vendor/supplying plant' column.\n",
    "\n",
    "Once this process done, remove the 'Vendor/supplying plant' column since it is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df1[\"Vendor/supplying plant\"].str.split(\" \", n = 1, expand = True) \n",
    "df1.insert(0,'Vendor Code', new[0]);\n",
    "df1.insert(1,'Vendor', new[1]);\n",
    "df1.drop(columns=['Vendor/supplying plant']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Classify each PO according to CAPEX/OPEX category.\n",
    "\n",
    "Use values from 'Acc Assignment Cat.' as reference for classification.\n",
    "- CAPEX (A, N, P, X)\n",
    "- OPEX (F, K, Blank)\n",
    "\n",
    "Add a new column called 'Capex/Opex' at the end of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Capex/Opex Category\n",
    "df1.loc[ (df1['Acct Assignment Cat.'] == 'A') |\n",
    "        (df1['Acct Assignment Cat.'] == 'N') |\n",
    "        (df1['Acct Assignment Cat.'] == 'P') |\n",
    "        (df1['Acct Assignment Cat.'] == 'X'),'Capex/Opex'] = 'CAPEX'\n",
    "\n",
    "df1.loc[ (df1['Acct Assignment Cat.'] == 'F') |\n",
    "        (df1['Acct Assignment Cat.'] == 'K') |\n",
    "        (df1['Acct Assignment Cat.'] == ''),'Capex/Opex'] = 'OPEX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculate Aging, PO Category & PO Year\n",
    "\n",
    "Add 2 new columns to input the Aging info:\n",
    "- 'Aging' = shows aging in number of days\n",
    "- 'Aging (Months & Days)' = shows aging in number of months and remaining days\n",
    "\n",
    "Check PO Category if the value in 'Document Date' column is similar to current year. If not then PO < Current Year\n",
    "\n",
    "Check PO Year using the 'Document Date' column. Extract year info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "def calculate_aging_days(doc_date,date_now):\n",
    "    po_date = datetime.datetime.strptime(doc_date, '%d/%m/%Y')\n",
    "    delta = now - po_date\n",
    "    return int(delta.days)\n",
    "\n",
    "def calculate_aging_months_days(aging_days):\n",
    "    months = int(aging_days/30)\n",
    "    remaining_days = int(aging_days%30)\n",
    "    return str(months) + ' months ' + str(remaining_days) + ' days'\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "df1['Aging Days'] = df1.apply(lambda row: calculate_aging_days(row['Document Date'],now),axis=1)\n",
    "df1['PO Year'] =  datetime.datetime.now().year\n",
    "df1['Aging (Months & Days)'] = df1.apply(lambda row: calculate_aging_months_days(row['Aging Days']),axis=1)\n",
    "\n",
    "df1['Aging Days'].head()\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Calculate Aging Category\n",
    "\n",
    "Classify each PO into the following categories:\n",
    "- ( <6 Months )\n",
    "- ( >6 Months )\n",
    "- ( >18 Months )\n",
    "\n",
    "Add a new column 'Aging Category' at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1.loc[ (df1['Aging Days'] <= 182),'Aging Category'] = '<6 Months'\n",
    "df1.loc[ (df1['Aging Days'] > 182) & (df1['Aging Days'] < 540),'Aging Category'] = '>6 Months'\n",
    "df1.loc[ (df1['Aging Days'] > 540),'Aging Category'] = '>18 Months'\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Assign GR status\n",
    "\n",
    "Status can either be 'Open' or 'Closed' depending on there are still value to be delivered. Use the column 'Still to be delivered (value)' as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1['Still to be delivered (value)'] = df1['Still to be delivered (value)'].str.replace(',','')\n",
    "df1['Still to be delivered (value)'] = df1['Still to be delivered (value)'].astype(float)\n",
    "df1.loc[ (df1['Still to be delivered (value)'] > 0),'GR Status'] = 'Open'\n",
    "df1.loc[ (df1['Still to be delivered (value)'] == 0),'GR Status'] = 'Closed'\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Assign GRIR Status\n",
    "Status can be either 'Open' or 'Closed' depending on value in column 'Still to be invoiced (val.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Still to be invoiced (val.)'] = df1['Still to be invoiced (val.)'].str.replace(',','')\n",
    "df1['Still to be invoiced (val.)'] = df1['Still to be invoiced (val.)'].astype(float)\n",
    "df1['GRIR Status'] = df1['Still to be invoiced (val.)'].apply(lambda x: 'Open' if x > -0.1 and x < 0.1 else 'Closed')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Assign PO Category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.loc[ (df1['GR Status'] == 'Closed') & (df1['GRIR Status'] == 'Closed'),'PO Status'] = 'Closed'\n",
    "# df1.loc[ (df1['GR Status'] == 'Open') | (df1['GRIR Status'] == 'Open'),'PO Status'] = 'Open'\n",
    "\n",
    "df1['PO Status'] = np.where((df1['GR Status'] == 'Closed') & (df1['GRIR Status'] == 'Closed'), 'Closed', 'Open')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Calculate Still to be delivered (MYR-Value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set USD Currency rate here.\n",
    "usd_currency_rate = 4.1\n",
    "\n",
    "df1['Still to be delivered (MYR-Value)'] = np.where(df1['Currency']== 'USD', df1['Still to be delivered (value)']*usd_currency_rate, df1['Still to be delivered (value)'])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B : Prepare Report\n",
    "\n",
    "### 1. Write data to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column and create new dataframe\n",
    "df_final = df1.drop(columns=['Vendor/supplying plant','Outline Agreement', 'Deletion Indicator','Req. Tracking Number'])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "output_filename = 'output/final.xlsx'\n",
    "\n",
    "df_final.to_excel(output_filename, sheet_name='data', engine='xlsxwriter',index=False)\n",
    "print('done')\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# df1.to_csv('output/final_csv.csv', index=False)\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
